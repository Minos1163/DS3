"""
ç®€åŒ–ç‰ˆæ·±åº¦åˆ†æ - åŸºäºKçº¿æ•°æ®å’Œäº¤æ˜“ç»“æœ
"""
import pandas as pd
import numpy as np
import glob
import os
import json
from datetime import datetime

def analyze_detailed(csv_file, log_file):
    """è¯¦ç»†åˆ†æå¸‚åœºçŠ¶æ€å’Œäº¤æ˜“æ—¶æœº"""
    
    # è¯»å–CSVæ•°æ®
    df = pd.read_csv(csv_file)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š è¯¦ç»†å¸‚åœºçŠ¶æ€åˆ†æ")
    print(f"{'='*70}\n")
    
    # 1. å¸‚åœºçŠ¶æ€åˆ†æ
    print("ğŸ“ˆ 1. å¸‚åœºæ³¢åŠ¨ç‰¹å¾:")
    print(f"   äº¤æ˜“å‘¨æœŸ: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
    print(f"   æ—¶é—´è·¨åº¦: {(df['timestamp'].max() - df['timestamp'].min()).days} å¤© {((df['timestamp'].max() - df['timestamp'].min()).seconds // 3600)} å°æ—¶")
    print(f"   Kçº¿æ•°é‡: {len(df)} æ ¹")
    
    # ä»·æ ¼ç»Ÿè®¡
    print(f"\nğŸ’° 2. ä»·æ ¼ç»Ÿè®¡:")
    print(f"   å¼€ç›˜ä»·: {df['open'].iloc[0]:.2f}")
    print(f"   æ”¶ç›˜ä»·: {df['close'].iloc[-1]:.2f}")
    print(f"   æœ€é«˜ä»·: {df['high'].max():.2f}")
    print(f"   æœ€ä½ä»·: {df['low'].min():.2f}")
    print(f"   æ¶¨è·Œå¹…: {(df['close'].iloc[-1] - df['open'].iloc[0]) / df['open'].iloc[0] * 100:+.2f}%")
    
    # RSIåˆ†æ - éœ€è¦ä»æ—¥å¿—ä¸­é‡æ–°è®¡ç®—
    print(f"\nğŸ“Š 3. ä»æ—¥å¿—æå–çš„å…³é”®æŒ‡æ ‡åˆ†å¸ƒ:")
    
    # ä»æ—¥å¿—ä¸­è§£æKçº¿ä¿¡æ¯
    rsi_values = []
    macd_values = []
    
    with open(log_file, 'r', encoding='utf-8') as f:
        for line in f:
            if ' | RSI=' in line and 'MACD=' in line:
                try:
                    rsi_match = line.split('RSI=')[1].split(' ')[0]
                    macd_match = line.split('MACD=')[1].split(' ')[0]
                    rsi_values.append(float(rsi_match))
                    macd_values.append(float(macd_match))
                except:
                    pass
    
    if rsi_values:
        print(f"   RSIç»Ÿè®¡:")
        print(f"     å¹³å‡å€¼: {np.mean(rsi_values):.1f}")
        print(f"     æœ€å¤§å€¼: {np.max(rsi_values):.1f}")
        print(f"     æœ€å°å€¼: {np.min(rsi_values):.1f}")
        print(f"     è¶…å–(<35): {len([x for x in rsi_values if x < 35])} æ¬¡")
        print(f"     è¶…ä¹°(>70): {len([x for x in rsi_values if x > 70])} æ¬¡")
        print(f"     ä¸­ç«‹(47-53): {len([x for x in rsi_values if 47 <= x <= 53])} æ¬¡")
    
    if macd_values:
        print(f"   MACDç»Ÿè®¡:")
        print(f"     å¹³å‡å€¼: {np.mean(macd_values):+.3f}")
        print(f"     æ­£å€¼: {len([x for x in macd_values if x > 0])} æ¬¡ ({len([x for x in macd_values if x > 0])/len(macd_values)*100:.1f}%)")
        print(f"     è´Ÿå€¼: {len([x for x in macd_values if x < 0])} æ¬¡ ({len([x for x in macd_values if x < 0])/len(macd_values)*100:.1f}%)")
    
    # 4. æ³¢åŠ¨ç‡åˆ†æ
    print(f"\nğŸ’¨ 4. æ³¢åŠ¨ç‡åˆ†æ:")
    df['atr'] = (df['high'] - df['low']).rolling(14).mean()
    print(f"   å¹³å‡ATR: {df['atr'].mean():.4f} ({df['atr'].mean()/df['close'].mean()*100:.2f}%)")
    print(f"   æœ€å¤§ATR: {df['atr'].max():.4f}")
    print(f"   æœ€å°ATR: {df['atr'].min():.4f}")
    
    # 5. ä»æ—¥å¿—è§£æäº¤æ˜“ä¿¡æ¯
    print(f"\n{'='*70}")
    print(f"ğŸ’° äº¤æ˜“æ‰§è¡Œåˆ†æ")
    print(f"{'='*70}\n")
    
    trades_info = parse_trades_from_log(log_file)
    
    if trades_info:
        print(f"ğŸ“Š 5. äº¤æ˜“ç»Ÿè®¡:")
        print(f"   æ€»äº¤æ˜“: {len(trades_info)} ç¬”")
        
        winning = [t for t in trades_info if t['pnl'] > 0]
        losing = [t for t in trades_info if t['pnl'] < 0]
        
        print(f"   èƒœåˆ©: {len(winning)} ç¬” ({len(winning)/len(trades_info)*100:.1f}%)")
        print(f"   å¤±è´¥: {len(losing)} ç¬” ({len(losing)/len(trades_info)*100:.1f}%)")
        
        total_pnl = sum([t['pnl'] for t in trades_info])
        print(f"   æ€»ç›ˆäº: {total_pnl:+.2f} USDT ({total_pnl/100*100:+.2f}%)")
        
        if winning:
            print(f"   å¹³å‡èƒœåˆ©: {np.mean([t['pnl'] for t in winning]):+.2f} USDT")
        if losing:
            print(f"   å¹³å‡äºæŸ: {np.mean([t['pnl'] for t in losing]):+.2f} USDT")
        
        # åˆ†æå¼€ä»“æ¡ä»¶
        print(f"\nğŸ¯ 6. å¼€ä»“æ¡ä»¶åˆ†æ:")
        entry_reasons = {}
        for t in trades_info:
            reason = t['reason_entry']
            if reason not in entry_reasons:
                entry_reasons[reason] = {'total': 0, 'win': 0, 'pnl': 0}
            entry_reasons[reason]['total'] += 1
            entry_reasons[reason]['pnl'] += t['pnl']
            if t['pnl'] > 0:
                entry_reasons[reason]['win'] += 1
        
        for reason, stats in sorted(entry_reasons.items(), key=lambda x: x[1]['total'], reverse=True):
            win_rate = stats['win'] / stats['total'] * 100
            avg_pnl = stats['pnl'] / stats['total']
            print(f"   {reason[:50]:50s}: {stats['total']} ç¬”, èƒœç‡{win_rate:5.1f}%, å¹³å‡{avg_pnl:+.2f}")
        
        # åˆ†ææŒä»“æ—¶é—´
        print(f"\nâ±ï¸ 7. æŒä»“æ—¶é—´åˆ†æ:")
        holding_bars = []
        for t in trades_info:
            entry = pd.to_datetime(t['entry_time'])
            exit = pd.to_datetime(t['exit_time'])
            bars = (exit - entry).total_seconds() / 300
            holding_bars.append(bars)
        
        if holding_bars:
            print(f"   å¹³å‡æŒä»“: {np.mean(holding_bars):.1f} æ ¹Kçº¿ ({np.mean(holding_bars)*5:.0f} åˆ†é’Ÿ)")
            print(f"   æœ€é•¿æŒä»“: {np.max(holding_bars):.1f} æ ¹Kçº¿ ({np.max(holding_bars)*5:.0f} åˆ†é’Ÿ)")
            print(f"   æœ€çŸ­æŒä»“: {np.min(holding_bars):.1f} æ ¹Kçº¿ ({np.min(holding_bars)*5:.0f} åˆ†é’Ÿ)")
            
            short_holding = [h for h in holding_bars if h < 10]
            long_holding = [h for h in holding_bars if h >= 10]
            
            if short_holding:
                short_pnl = sum([t['pnl'] for t, h in zip(trades_info, holding_bars) if h < 10])
                print(f"   çŸ­æŒä»“(<10æ ¹): {len(short_holding)} æ¬¡, å¹³å‡ç›ˆäº {short_pnl/len(short_holding):+.2f}")
            
            if long_holding:
                long_pnl = sum([t['pnl'] for t, h in zip(trades_info, holding_bars) if h >= 10])
                print(f"   é•¿æŒä»“(â‰¥10æ ¹): {len(long_holding)} æ¬¡, å¹³å‡ç›ˆäº {long_pnl/len(long_holding):+.2f}")

def parse_trades_from_log(log_file):
    """ä»æ—¥å¿—ä¸­æå–äº¤æ˜“ä¿¡æ¯"""
    trades = []
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æŸ¥æ‰¾æ‰€æœ‰äº¤æ˜“å—
    import re
    
    # æŸ¥æ‰¾å¹³ä»“ä¿¡æ¯
    close_pattern = r'([âœ…âŒğŸ›‘]) \[([^\]]+)\] å¹³ä»“ (LONG|SHORT).*?å¼€ä»“ä»·: ([\d.]+).*?å¹³ä»“ä»·: ([\d.]+).*?ç›ˆäº: ([\d.-]+).*?åŸå› : (.+?)(?:\n|='
    matches = re.findall(close_pattern, content, re.DOTALL)
    
    for match in matches:
        status, exit_time, direction, entry_price, exit_price, pnl, reason = match
        
        # æ‰¾åˆ°å¯¹åº”çš„å¼€ä»“æ—¶é—´å’ŒåŸå› 
        entry_pattern = rf'ğŸ“‰ \[([^\]]+)\] å¼€{direction[0:2]if direction=="LONG" else "ç©º"}ä»“.*?åŸå› : (.+?)(?:\n|=)'
        entry_matches = re.findall(entry_pattern, content, re.DOTALL)
        
        if entry_matches:
            entry_time = entry_matches[-1][0] if entry_matches else exit_time
            reason_entry = entry_matches[-1][1] if entry_matches else reason
            
            trades.append({
                'entry_time': entry_time,
                'exit_time': exit_time,
                'direction': direction,
                'entry_price': float(entry_price),
                'exit_price': float(exit_price),
                'pnl': float(pnl),
                'reason_entry': reason_entry,
                'reason_exit': reason.strip()
            })
    
    return trades

def print_optimization_guide():
    """æ‰“å°ä¼˜åŒ–æŒ‡å—"""
    print(f"\n{'='*70}")
    print(f"âš™ï¸ å‚æ•°ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºåˆ†æç»“æœï¼‰")
    print(f"{'='*70}\n")
    
    print("ğŸ”´ ä¼˜å…ˆçº§1 - å¼€ä»“ç­–ç•¥ä¼˜åŒ– (é¢„æœŸ+50-100% äº¤æ˜“é‡):")
    print("""
   1. é™ä½ä¿¡å·é—¨æ§›: 4/6 â†’ 3/6
      â€¢ å½“å‰å¤ªä¸¥æ ¼ï¼Œå¾ˆå¤šæœºä¼šé”™è¿‡
      â€¢ å»ºè®®: signal_threshold = 3
      â€¢ ä»£ç ä½ç½®: backtest_ai_optimized.py line ~280
    
   2. ç¼©çŸ­äº¤æ˜“å†·å´æœŸ: 8æ ¹ â†’ 4æ ¹
      â€¢ å½“å‰å†·å´æœŸå¯¼è‡´æœºä¼šä¸§å¤±
      â€¢ å»ºè®®: min_bars_between_trades = 4
      â€¢ ä»£ç ä½ç½®: backtest_ai_optimized.py line ~60
    """)
    
    print("ğŸŸ¡ ä¼˜å…ˆçº§2 - å¹³ä»“ç­–ç•¥ä¼˜åŒ– (é¢„æœŸ+30-50% æ”¶ç›Š):")
    print("""
   1. æ”¾å®½å¹³ä»“æ¡ä»¶: RSI 47-53 â†’ RSI 40-60
      â€¢ å½“å‰å¹³ä»“å¤ªæ—©ï¼Œåˆ‡æ–­åˆ©æ¶¦
      â€¢ å»ºè®®: æ”¹ä¸ºåŠ¨æ€å¹³ä»“
        - èƒœåˆ©è¶‹åŠ¿ä¸­ï¼Œæ”¹ä¸ºæ­¢ç›ˆåˆ¶
        - æ­¢ç›ˆ: take_profit_pct = 3.0
      â€¢ ä»£ç ä½ç½®: backtest_ai_optimized.py line ~320
    
   2. ä¼˜åŒ–æ­¢æŸ: 1.5% â†’ 2.0%
      â€¢ å½“å‰æ­¢æŸåç´§ï¼Œè™šå‡è§¦å‘
      â€¢ å»ºè®®: stop_loss_pct = 2.0
      â€¢ ä»£ç ä½ç½®: backtest_ai_optimized.py line ~55
    """)
    
    print("ğŸŸ¢ ä¼˜å…ˆçº§3 - é«˜çº§ä¼˜åŒ– (é¢„æœŸ+10-20% æ”¶ç›Š):")
    print("""
   1. ä»“ä½ç®¡ç†
      â€¢ å¼ºä¿¡å·(5-6/6) â†’ 30% ä»“ä½
      â€¢ ä¸­ç­‰ä¿¡å·(4/6) â†’ 25% ä»“ä½
      â€¢ å¼±ä¿¡å·(3/6) â†’ 15% ä»“ä½
    
   2. æ—¶é—´è¿‡æ»¤
      â€¢ é¿å… 22:00-02:00 äº¤æ˜“ï¼ˆæµåŠ¨æ€§å·®ï¼‰
      â€¢ ä¼˜å…ˆ 08:00-16:00ï¼ˆäºšæ´²å’Œæ¬§æ´²äº¤æ˜“æ—¶æ®µï¼‰
    
   3. è¶‹åŠ¿ç¡®è®¤
      â€¢ åªåœ¨MACDä¸ºè´Ÿå€¼æ—¶åšç©ºï¼ˆå½“å‰å¸‚åœºä¸‹é™è¶‹åŠ¿ï¼‰
      â€¢ åªåœ¨MACDä¸ºæ­£å€¼æ—¶åšå¤šï¼ˆæœªæ¥å¯ç”¨ï¼‰
    """)

if __name__ == '__main__':
    # æ‰¾åˆ°æœ€æ–°æ–‡ä»¶
    log_files = glob.glob('backtest_log_SOLUSDT_*.txt')
    csv_files = glob.glob('market_data_SOLUSDT_*.csv')
    
    if not log_files or not csv_files:
        print("âŒ æ‰¾ä¸åˆ°æ—¥å¿—æˆ–CSVæ–‡ä»¶")
    else:
        latest_log = max(log_files, key=os.path.getctime)
        latest_csv = max(csv_files, key=os.path.getctime)
        
        print(f"ğŸ“‚ åˆ†ææ–‡ä»¶:")
        print(f"   æ—¥å¿—: {latest_log}")
        print(f"   æ•°æ®: {latest_csv}")
        
        analyze_detailed(latest_csv, latest_log)
        print_optimization_guide()
