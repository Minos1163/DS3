"""åˆ†æå›æµ‹æ—¥å¿—ï¼Œç»Ÿè®¡å„ç§å†³ç­–ä¿¡æ¯"""
import re
from collections import Counter

def analyze_log(log_file):
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç»Ÿè®¡Kçº¿æ•°é‡
    kline_pattern = r'^\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] O='
    klines = re.findall(kline_pattern, content, re.MULTILINE)
    print(f"\n{'='*60}")
    print(f"ğŸ“Š å›æµ‹æ—¥å¿—åˆ†ææŠ¥å‘Š")
    print(f"{'='*60}\n")
    print(f"âœ… Kçº¿è®°å½•æ€»æ•°: {len(klines)} æ ¹")
    
    # ç»Ÿè®¡AIå†³ç­–
    decision_pattern = r'AIå†³ç­–: (\w+)'
    decisions = re.findall(decision_pattern, content)
    decision_counts = Counter(decisions)
    
    print(f"\nğŸ“ˆ AIå†³ç­–ç»Ÿè®¡:")
    print(f"   æ€»å†³ç­–æ¬¡æ•°: {len(decisions)}")
    for decision, count in decision_counts.most_common():
        print(f"   {decision}: {count} æ¬¡")
    
    # ç»Ÿè®¡äº¤æ˜“
    open_long = len(re.findall(r'å¼€å¤šä»“', content))
    open_short = len(re.findall(r'å¼€ç©ºä»“', content))
    close_trade = len(re.findall(r'å¹³ä»“', content))
    
    print(f"\nğŸ’° äº¤æ˜“ç»Ÿè®¡:")
    print(f"   å¼€å¤šä»“: {open_long} æ¬¡")
    print(f"   å¼€ç©ºä»“: {open_short} æ¬¡")
    print(f"   å¹³ä»“: {close_trade} æ¬¡")
    print(f"   æ€»äº¤æ˜“: {open_long + open_short} ç¬”")
    
    # åˆ†æå†³ç­–åŸå› 
    reason_pattern = r'AIå†³ç­–: \w+ \(ç½®ä¿¡åº¦:[\d.]+\) - (.+?)(?:\n|$)'
    reasons = re.findall(reason_pattern, content)
    
    # ç»Ÿè®¡SELL_OPENå†³ç­–çš„ä¿¡å·å¼ºåº¦
    sell_signal_pattern = r'åšç©ºä¿¡å·\((\d+)/6\)'
    sell_signals = re.findall(sell_signal_pattern, content)
    if sell_signals:
        signal_counts = Counter(sell_signals)
        print(f"\nğŸ“‰ åšç©ºä¿¡å·å¼ºåº¦åˆ†å¸ƒ:")
        for signal, count in sorted(signal_counts.items(), key=lambda x: int(x[0]), reverse=True):
            print(f"   {signal}/6 æŒ‡æ ‡æ»¡è¶³: {count} æ¬¡")
    
    # ç»Ÿè®¡å¹³ä»“åŸå› 
    close_pattern = r'å¹³ä»“ (LONG|SHORT)\n.*?åŸå› : (.+?)(?:\n|$)'
    closes = re.findall(close_pattern, content, re.DOTALL)
    if closes:
        close_reasons = Counter([reason.split('\n')[0].strip() for _, reason in closes])
        print(f"\nâŒ å¹³ä»“åŸå› ç»Ÿè®¡:")
        for reason, count in close_reasons.most_common(5):
            print(f"   {reason}: {count} æ¬¡")
    
    # è®¡ç®—äº¤æ˜“é¢‘ç‡
    if klines:
        trade_frequency = len(klines) / (open_long + open_short) if (open_long + open_short) > 0 else 0
        print(f"\nâ±ï¸ äº¤æ˜“é¢‘ç‡:")
        print(f"   å¹³å‡æ¯ {trade_frequency:.1f} æ ¹Kçº¿å‘ç”Ÿä¸€æ¬¡äº¤æ˜“")
        print(f"   ç›¸å½“äºæ¯ {trade_frequency * 5:.1f} åˆ†é’Ÿä¸€æ¬¡äº¤æ˜“")
        print(f"   äº¤æ˜“ç‡: {(open_long + open_short) / len(klines) * 100:.2f}%")
    
    # åˆ†æä¸ºä»€ä¹ˆäº¤æ˜“å°‘
    print(f"\nğŸ’¡ äº¤æ˜“æ¬¡æ•°å°‘çš„åŸå› åˆ†æ:")
    print(f"   1. ä¿¡å·é—¨æ§›: éœ€è¦è‡³å°‘4/6ä¸ªæŒ‡æ ‡åŒæ—¶æ»¡è¶³æ‰èƒ½å¼€ä»“")
    print(f"   2. äº¤æ˜“å†·å´: æ¯æ¬¡äº¤æ˜“åéœ€è¦ç­‰å¾…8æ ¹Kçº¿(40åˆ†é’Ÿ)")
    print(f"   3. RSIå¹³ä»“: RSIå›åˆ°47-53ä¸­æ€§åŒºé—´å°±ä¼šå¹³ä»“")
    print(f"   4. å¸‚åœºæ¡ä»¶: å½“å‰å¸‚åœºå¯èƒ½ä¸æ»¡è¶³åšç©ºæ¡ä»¶çš„æ—¶é—´è¾ƒå¤š")
    
    # ç»Ÿè®¡ä»“ä½æƒ…å†µ
    position_lines = re.findall(r'ä»“ä½:(\S+)', content)
    position_counts = Counter(position_lines)
    print(f"\nğŸ“Š ä»“ä½åˆ†å¸ƒ:")
    for pos, count in position_counts.most_common():
        percent = count / len(position_lines) * 100 if position_lines else 0
        print(f"   {pos}: {count} æ¬¡ ({percent:.1f}%)")

if __name__ == '__main__':
    import glob
    import os
    
    # æ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
    log_files = glob.glob('backtest_log_SOLUSDT_*.txt')
    if log_files:
        latest_log = max(log_files, key=os.path.getctime)
        print(f"åˆ†ææ–‡ä»¶: {latest_log}")
        analyze_log(latest_log)
    else:
        print("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
